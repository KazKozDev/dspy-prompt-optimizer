"""
Agent Configuration - Central config dataclass for DSPy Meta-Agent.
Holds all decisions made by the agent (or manually by user).
"""

from dataclasses import dataclass, field
from enum import Enum
from typing import Any, Dict, List, Optional


class PipelineType(str, Enum):
    """Types of DSPy pipelines."""
    PREDICT = "predict"                    # Simple dspy.Predict
    CHAIN_OF_THOUGHT = "chain_of_thought"  # dspy.ChainOfThought
    REACT = "react"                        # dspy.ReAct with tools
    RAG = "rag"                            # Retrieve + Generate
    MULTI_STAGE = "multi_stage"            # Custom multi-step pipeline


class MetricType(str, Enum):
    """Types of evaluation metrics."""
    EXACT_MATCH = "exact_match"
    TOKEN_F1 = "token_f1"
    SEMANTIC_SIMILARITY = "semantic_similarity"
    LLM_JUDGE = "llm_judge"
    CUSTOM = "custom"


class OptimizerType(str, Enum):
    """Types of DSPy optimizers."""
    BOOTSTRAP_FEW_SHOT = "BootstrapFewShot"
    BOOTSTRAP_RANDOM_SEARCH = "BootstrapFewShotWithRandomSearch"
    MIPRO_V2 = "MIPROv2"
    COPRO = "COPRO"
    DISTILLATION = "Distillation"


class TaskType(str, Enum):
    """Types of NLP tasks."""
    CLASSIFICATION = "classification"
    EXTRACTION = "extraction"
    SUMMARIZATION = "summarization"
    REASONING = "reasoning"
    QA = "qa"
    RAG = "rag"
    GENERATION = "generation"
    ROUTING = "routing"
    CODE = "code"


class ComplexityLevel(str, Enum):
    """Task complexity levels."""
    LOW = "low"
    MEDIUM = "medium"
    HIGH = "high"


@dataclass
class TaskAnalysis:
    """Result of task analysis."""
    task_type: TaskType = TaskType.REASONING
    domain: str = "general"
    complexity: ComplexityLevel = ComplexityLevel.MEDIUM
    input_fields: List[str] = field(default_factory=lambda: ["text"])
    output_fields: List[str] = field(default_factory=lambda: ["result"])
    
    needs_retrieval: bool = False
    needs_chain_of_thought: bool = False
    needs_tools: bool = False
    needs_multi_stage: bool = False
    
    suggested_tools: List[str] = field(default_factory=list)
    suggested_pipeline_template: Optional[str] = None
    
    confidence: float = 0.8
    reasoning: str = ""


@dataclass
class PipelineConfig:
    """Configuration for the DSPy pipeline."""
    pipeline_type: PipelineType = PipelineType.CHAIN_OF_THOUGHT
    template_name: Optional[str] = None  # e.g., "outline_draft_revise"
    
    stages: List[Dict[str, Any]] = field(default_factory=list)
    
    retriever_type: Optional[str] = None  # "faiss", "chroma", "colbert"
    retriever_k: int = 5
    
    tools: List[str] = field(default_factory=list)  # ["calculator", "web_search"]


@dataclass
class MetricConfig:
    """Configuration for evaluation metrics."""
    metric_type: MetricType = MetricType.TOKEN_F1
    
    llm_judge_model: Optional[str] = None  # Model for LLM-as-judge
    llm_judge_criteria: Optional[str] = None  # Custom criteria
    
    semantic_model: Optional[str] = None  # Embedding model for semantic similarity
    
    custom_metric_code: Optional[str] = None  # Python code for custom metric


@dataclass
class OptimizerConfig:
    """Configuration for DSPy optimizer."""
    optimizer_type: OptimizerType = OptimizerType.BOOTSTRAP_FEW_SHOT
    
    max_bootstrapped_demos: int = 4
    max_labeled_demos: int = 16
    max_rounds: int = 1
    num_candidates: int = 16
    
    teacher_model: Optional[str] = None  # For distillation
    student_model: Optional[str] = None  # For distillation
    distillation_samples: int = 100


@dataclass
class AgentConfig:
    """
    Central configuration for DSPy Meta-Agent.
    
    Contains all decisions about how to build and optimize the DSPy program.
    Can be auto-generated by the agent or manually configured by user.
    """
    
    mode: str = "auto"  # "auto" or "manual"
    
    business_task: str = ""
    target_model: str = ""
    optimizer_model: str = ""
    
    task_analysis: TaskAnalysis = field(default_factory=TaskAnalysis)
    pipeline_config: PipelineConfig = field(default_factory=PipelineConfig)
    metric_config: MetricConfig = field(default_factory=MetricConfig)
    optimizer_config: OptimizerConfig = field(default_factory=OptimizerConfig)
    
    quality_profile: str = "BALANCED"  # FAST_CHEAP, BALANCED, HIGH_QUALITY
    
    # Distillation settings
    enable_distillation: bool = False
    teacher_model: str = "openai/gpt-4o"
    distillation_samples: int = 100
    
    agent_reasoning: List[str] = field(default_factory=list)
    
    def to_dict(self) -> Dict[str, Any]:
        """Convert config to dictionary for serialization."""
        return {
            "mode": self.mode,
            "business_task": self.business_task,
            "target_model": self.target_model,
            "optimizer_model": self.optimizer_model,
            "quality_profile": self.quality_profile,
            "task_analysis": {
                "task_type": self.task_analysis.task_type.value,
                "domain": self.task_analysis.domain,
                "complexity": self.task_analysis.complexity.value,
                "input_fields": self.task_analysis.input_fields,
                "output_fields": self.task_analysis.output_fields,
                "needs_retrieval": self.task_analysis.needs_retrieval,
                "needs_chain_of_thought": self.task_analysis.needs_chain_of_thought,
                "needs_tools": self.task_analysis.needs_tools,
                "needs_multi_stage": self.task_analysis.needs_multi_stage,
                "suggested_tools": self.task_analysis.suggested_tools,
                "confidence": self.task_analysis.confidence,
                "reasoning": self.task_analysis.reasoning,
            },
            "pipeline_config": {
                "pipeline_type": self.pipeline_config.pipeline_type.value,
                "template_name": self.pipeline_config.template_name,
                "stages": self.pipeline_config.stages,
                "retriever_type": self.pipeline_config.retriever_type,
                "retriever_k": self.pipeline_config.retriever_k,
                "tools": self.pipeline_config.tools,
            },
            "metric_config": {
                "metric_type": self.metric_config.metric_type.value,
                "llm_judge_model": self.metric_config.llm_judge_model,
                "llm_judge_criteria": self.metric_config.llm_judge_criteria,
            },
            "optimizer_config": {
                "optimizer_type": self.optimizer_config.optimizer_type.value,
                "max_bootstrapped_demos": self.optimizer_config.max_bootstrapped_demos,
                "max_labeled_demos": self.optimizer_config.max_labeled_demos,
                "teacher_model": self.optimizer_config.teacher_model,
                "student_model": self.optimizer_config.student_model,
            },
            "agent_reasoning": self.agent_reasoning,
        }
    
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> "AgentConfig":
        """Create config from dictionary."""
        config = cls()
        config.mode = data.get("mode", "auto")
        config.business_task = data.get("business_task", "")
        config.target_model = data.get("target_model", "")
        config.optimizer_model = data.get("optimizer_model", "")
        config.quality_profile = data.get("quality_profile", "BALANCED")
        
        if "task_analysis" in data:
            ta = data["task_analysis"]
            config.task_analysis = TaskAnalysis(
                task_type=TaskType(ta.get("task_type", "reasoning")),
                domain=ta.get("domain", "general"),
                complexity=ComplexityLevel(ta.get("complexity", "medium")),
                input_fields=ta.get("input_fields", ["text"]),
                output_fields=ta.get("output_fields", ["result"]),
                needs_retrieval=ta.get("needs_retrieval", False),
                needs_chain_of_thought=ta.get("needs_chain_of_thought", False),
                needs_tools=ta.get("needs_tools", False),
                needs_multi_stage=ta.get("needs_multi_stage", False),
                suggested_tools=ta.get("suggested_tools", []),
                confidence=ta.get("confidence", 0.8),
                reasoning=ta.get("reasoning", ""),
            )
        
        if "pipeline_config" in data:
            pc = data["pipeline_config"]
            config.pipeline_config = PipelineConfig(
                pipeline_type=PipelineType(pc.get("pipeline_type", "chain_of_thought")),
                template_name=pc.get("template_name"),
                stages=pc.get("stages", []),
                retriever_type=pc.get("retriever_type"),
                retriever_k=pc.get("retriever_k", 5),
                tools=pc.get("tools", []),
            )
        
        if "metric_config" in data:
            mc = data["metric_config"]
            config.metric_config = MetricConfig(
                metric_type=MetricType(mc.get("metric_type", "token_f1")),
                llm_judge_model=mc.get("llm_judge_model"),
                llm_judge_criteria=mc.get("llm_judge_criteria"),
            )
        
        if "optimizer_config" in data:
            oc = data["optimizer_config"]
            config.optimizer_config = OptimizerConfig(
                optimizer_type=OptimizerType(oc.get("optimizer_type", "BootstrapFewShot")),
                max_bootstrapped_demos=oc.get("max_bootstrapped_demos", 4),
                max_labeled_demos=oc.get("max_labeled_demos", 16),
                teacher_model=oc.get("teacher_model"),
                student_model=oc.get("student_model"),
            )
        
        config.agent_reasoning = data.get("agent_reasoning", [])
        
        return config
